{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [ LG전자 H&A DX Intensive Course - Auto-Encoder for Anomaly Detection ]\n",
        "\n",
        "Auto-Encoder를 활용한 tabular anomaly detection"
      ],
      "metadata": {
        "id": "k2QWHn7xf0Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1e541AXa81DqeD-XpPhNWnWlewo8yjbOa"
      ],
      "metadata": {
        "id": "yI6lOg7PcLkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules"
      ],
      "metadata": {
        "id": "HqEmmmzZf34i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXT-DbuLEStn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
        "sns.set_theme(style=\"ticks\", rc=custom_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "R66Zb1C9f-ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "    # CUDA randomness\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
        "\n",
        "\n",
        "def train(\n",
        "    model, dataloader, criterion, optimizer, log_interval: int, device: str) -> list:\n",
        "\n",
        "    total_loss = []\n",
        "\n",
        "    model.train()\n",
        "    for i, (inputs, _) in enumerate(dataloader):\n",
        "\n",
        "        # convert device\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # model outputs\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(inputs, outputs).mean()\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # update model weights\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # log learning history\n",
        "        if i % log_interval == 0 or (i+1) == len(dataloader):\n",
        "            print(f\"{'TRAIN':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # average loss\n",
        "    avg_loss = np.mean(total_loss)\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "def test(\n",
        "    model, dataloader, criterion, log_interval: int, device: str) -> list:\n",
        "\n",
        "    # for auroc\n",
        "    total_loss = []\n",
        "    total_inputs = []\n",
        "    total_targets = []\n",
        "    total_outputs = []\n",
        "\n",
        "    torch_seed(223)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            # get inputs and targets\n",
        "            total_inputs.extend(inputs.numpy())\n",
        "            total_targets.extend(targets.numpy())\n",
        "\n",
        "            # convert device\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # model outputs\n",
        "            outputs = model(inputs)\n",
        "            total_outputs.extend(outputs.cpu().numpy())\n",
        "\n",
        "            # loss\n",
        "            loss = criterion(inputs, outputs).max(dim=-1)[0]\n",
        "            total_loss.extend(loss.cpu().numpy())\n",
        "\n",
        "            # log learning history\n",
        "            if i % log_interval == 0 or (i+1) == len(dataloader):\n",
        "                print(f\"{'TSET':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # total inputs, outputs, targets and loss\n",
        "    total_inputs = np.concatenate(total_inputs, axis=0)\n",
        "    total_outputs = np.concatenate(total_outputs, axis=0)\n",
        "    total_targets = np.array(total_targets).reshape(-1)\n",
        "    total_loss = np.array(total_loss).reshape(-1)\n",
        "\n",
        "    # auroc\n",
        "    if sum(total_targets) == 0:\n",
        "        auroc = 1.\n",
        "    else:\n",
        "        auroc = roc_auc_score(total_targets, total_loss)\n",
        "\n",
        "    # return\n",
        "    return auroc, total_inputs, total_outputs, total_loss\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model, trainloader, testloader, criterion, optimizer,\n",
        "    epochs: int, log_interval: int, device: str) -> list:\n",
        "\n",
        "    train_history = []\n",
        "    test_history_auroc = []\n",
        "\n",
        "    # fitting model\n",
        "    for i in range(epochs):\n",
        "        print(f'\\nEpoch: [{i+1}/{epochs}]')\n",
        "        train_loss = train(\n",
        "            model        = model,\n",
        "            dataloader   = trainloader,\n",
        "            criterion    = criterion,\n",
        "            optimizer    = optimizer,\n",
        "            log_interval = log_interval,\n",
        "            device       = device\n",
        "        )\n",
        "\n",
        "        test_auroc, total_inputs, total_outputs, total_loss = test(\n",
        "            model        = model,\n",
        "            dataloader   = testloader,\n",
        "            criterion    = criterion,\n",
        "            log_interval = log_interval,\n",
        "            device       = device\n",
        "        )\n",
        "\n",
        "        print(f'\\nTest AUROC: {test_auroc:.4f}')\n",
        "\n",
        "        train_history.append(train_loss)\n",
        "        test_history_auroc.append(test_auroc)\n",
        "\n",
        "    return train_history, test_history_auroc\n",
        "\n",
        "\n",
        "def figure(\n",
        "    all_train_history: list, all_test_history_auroc: list, all_exp_name: list) -> None:\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
        "\n",
        "    # train line plot\n",
        "    for i, (train_h, exp_name) in enumerate(zip(all_train_history, all_exp_name)):\n",
        "        sns.lineplot(\n",
        "            x     = range(1, len(train_h)+1),\n",
        "            y     = train_h,\n",
        "            label = exp_name,\n",
        "            ax    = ax[0]\n",
        "        )\n",
        "\n",
        "    # test AUROC lineplot\n",
        "    for i, (test_h, exp_name) in enumerate(zip(all_test_history_auroc, all_exp_name)):\n",
        "        sns.lineplot(\n",
        "            x     = range(1, len(test_h)+1),\n",
        "            y     = test_h,\n",
        "            label = exp_name,\n",
        "            ax    = ax[1]\n",
        "        )\n",
        "\n",
        "    # set y axis label\n",
        "    ax[0].set_ylabel('MSE Loss')\n",
        "    ax[1].set_ylabel('AUROC')\n",
        "\n",
        "    # set x axis label\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "\n",
        "    # set title\n",
        "    ax[0].set_title('Train loss history')\n",
        "    ax[1].set_title('Test AUROC history')\n",
        "\n",
        "    # set y value limit\n",
        "    max_train = np.max(all_train_history)\n",
        "\n",
        "    ax[0].set_ylim(0, max_train+0.01)\n",
        "    ax[1].set_ylim(0, 1)\n",
        "\n",
        "    # set legend\n",
        "    ax[0].legend(loc='upper left')\n",
        "    ax[1].legend(loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "b5GxGjTsf9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration for experiments"
      ],
      "metadata": {
        "id": "MGDwgU6Bx-Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # dataset 관련 parameters\n",
        "    datapath = './creditcard.csv'\n",
        "\n",
        "    # training 관련 parameters\n",
        "    epochs = 15\n",
        "    batch_size = 512\n",
        "    test_batch_size = 128\n",
        "    learning_rate = 0.001\n",
        "    num_workers = 2\n",
        "    log_interval = 2000\n",
        "\n",
        "    # device\n",
        "    device = 'cuda'\n",
        "\n",
        "    # seed\n",
        "    seed = 223\n",
        "\n",
        "cfg = Config()"
      ],
      "metadata": {
        "id": "iXiq4BOkx9yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset and dataloader\n",
        "\n",
        "**Feature Description**\n",
        "- **Time**: Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
        "- **V{ID}**: PCA results\n",
        "- **Amount**: Transaction amount\n",
        "- **Class**: 1 for fraudulent transactions, 0 otherwise"
      ],
      "metadata": {
        "id": "dRUckH_vyNIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(cfg.datapath)\n",
        "print('df.shape: ',df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_NunGNlssgz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum(axis=0)"
      ],
      "metadata": {
        "id": "H2vYC1WlyTsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN\n",
        "df = df.dropna()\n",
        "print('df.shape: ',df.shape)"
      ],
      "metadata": {
        "id": "mj4hcNzgynzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target\n",
        "pd.concat([df['Class'].value_counts(), df['Class'].value_counts(normalize=True)], axis=1)"
      ],
      "metadata": {
        "id": "AkMYq9PB5eG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into train and test dataset"
      ],
      "metadata": {
        "id": "mXblLcKQ3LPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, _ = train_test_split(df[df['Class']==0].index.values, test_size=0.1, random_state=cfg.seed)"
      ],
      "metadata": {
        "id": "GN1ts-o23IVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df.iloc[train_idx, :]\n",
        "df_test = df.drop(train_idx, axis=0)\n",
        "\n",
        "X_train = df_train.drop('Class', axis=1).values\n",
        "y_train = df_train['Class'].values\n",
        "\n",
        "X_test = df_test.drop('Class', axis=1).values\n",
        "y_test = df_test['Class'].values\n",
        "\n",
        "print('X_train.shape: ',X_train.shape)\n",
        "print('y_train.shape: ',y_train.shape)\n",
        "print('X_test.shape: ',X_test.shape)\n",
        "print('y_test.shape: ',y_test.shape)"
      ],
      "metadata": {
        "id": "WEtyv8H84GaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "t8DAuYZk-9Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "jAqn2eh2_A1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
        "testset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
        "testloader = DataLoader(testset, batch_size=cfg.test_batch_size, shuffle=False, num_workers=cfg.num_workers)"
      ],
      "metadata": {
        "id": "CPLHgxR-2xxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto-Encoder"
      ],
      "metadata": {
        "id": "vmrl77Ct5qoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, dims: list):\n",
        "        super().__init__()\n",
        "\n",
        "        dims = [input_dim] + dims\n",
        "\n",
        "        self.enc = nn.Sequential(*self.build_layer(dims=dims))\n",
        "        self.dec = nn.Sequential(*self.build_layer(dims=dims[::-1], up=True))\n",
        "        self.output = nn.Linear(in_features=input_dim, out_features=input_dim)\n",
        "\n",
        "    def build_layer(self, dims, up=False):\n",
        "        layer = []\n",
        "\n",
        "        for i in range(1, len(dims)):\n",
        "            if up:\n",
        "                layer_i = [\n",
        "                    nn.Linear(\n",
        "                        in_features  = dims[i-1],\n",
        "                        out_features = dims[i],\n",
        "                    ),\n",
        "                    nn.ReLU()\n",
        "                ]\n",
        "            else:\n",
        "                layer_i = [\n",
        "                    nn.Linear(\n",
        "                        in_features  = dims[i-1],\n",
        "                        out_features = dims[i],\n",
        "                    ),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "\n",
        "            layer.extend(layer_i)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    def encoder(self, x):\n",
        "        out = self.enc(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def decoder(self, out):\n",
        "        out = self.dec(out)\n",
        "        out = self.output(out)\n",
        "        out = F.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "G7LHiji620Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_seed(cfg.seed)\n",
        "ae = AutoEncoder(input_dim=X_train.shape[1], dims=[64, 32, 16])\n",
        "ae.to(cfg.device)\n",
        "print('load Auto-Encoder')\n",
        "print('The number of model parameters: ',sum([p.numel() for p in ae.parameters()]))\n",
        "\n",
        "# set reduction to none\n",
        "criterion = nn.MSELoss(reduction='none')\n",
        "optimizer = Adam(ae.parameters(), lr=cfg.learning_rate)"
      ],
      "metadata": {
        "id": "qB1W5nSn9KYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae"
      ],
      "metadata": {
        "id": "IYUFs_TR_nzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = next(iter(trainloader))\n",
        "inputs = inputs.to(cfg.device)\n",
        "print('inputs.shape: ',inputs.shape)\n",
        "\n",
        "outputs = ae(inputs)\n",
        "print('outputs.shape: ',outputs.shape)"
      ],
      "metadata": {
        "id": "G-Hp42wh9aod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_seed(cfg.seed)\n",
        "train_history, test_history_auroc = fit(\n",
        "    model        = ae,\n",
        "    trainloader  = trainloader,\n",
        "    testloader   = testloader,\n",
        "    criterion    = criterion,\n",
        "    optimizer    = optimizer,\n",
        "    epochs       = cfg.epochs,\n",
        "    log_interval = cfg.log_interval,\n",
        "    device       = cfg.device\n",
        ")"
      ],
      "metadata": {
        "id": "cuTBKBlM99Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_history = [train_history]\n",
        "all_test_history_auroc = [test_history_auroc]\n",
        "all_exp_name = ['AE']\n",
        "\n",
        "figure(\n",
        "    all_train_history      = all_train_history,\n",
        "    all_test_history_auroc = all_test_history_auroc,\n",
        "    all_exp_name           = all_exp_name\n",
        ")"
      ],
      "metadata": {
        "id": "vkdrkuq-9sAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_auroc, total_inputs, total_outputs, total_loss = test(\n",
        "    model        = ae,\n",
        "    dataloader   = testloader,\n",
        "    criterion    = criterion,\n",
        "    log_interval = cfg.log_interval,\n",
        "    device       = cfg.device\n",
        ")"
      ],
      "metadata": {
        "id": "ajJj4nm0FDRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TEST AUROC: {:.2%}'.format(test_auroc))"
      ],
      "metadata": {
        "id": "qr_7fh19Gw9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax(x):\n",
        "    return (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "df_test['pred'] = minmax(total_loss)\n",
        "\n",
        "sns.boxplot(x='Class', y='pred', hue='Class', data=df_test)\n",
        "plt.title('Anomaly Score Distribution')\n",
        "plt.xticks([0,1], ['Normal','Abnomral'])\n",
        "plt.ylabel('Anomaly Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d_QRFq2mHMEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}