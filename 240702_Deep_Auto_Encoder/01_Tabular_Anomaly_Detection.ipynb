{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2QWHn7xf0Zo"
   },
   "source": [
    "# [ LG에너지솔루션 DX Expert 양성과정 - Auto-Encoder #1]\n",
    "\n",
    "Auto-Encoder를 활용한 tabular anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 복습\n",
    "강의자료: Deep Auto-Encoder\n",
    "- `Auto-Encoder`: 입력과 출력이 동일한 인공 신경망 구조, 정보를 축약하는 파트를 인코더(Encoder)라 부르고 다시 복원하는 파트를 디코더(Decoder)라 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hwk0702/2024_LG_ES_External_Lecture/blob/main/240702_Deep_Auto_Encoder/image/AE01.png?raw=true\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 본 실습에서는 Auto-Encoder를 활용하여 tabular 데이터의 이상 탐지를 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI6lOg7PcLkN"
   },
   "outputs": [],
   "source": [
    "# Google Drive 파일 다운로드를 위한 gdown 패키지 설치\n",
    "!pip install gdown\n",
    "\n",
    "# 데이터 저장을 위한 디렉토리 생성\n",
    "!mkdir -p ./data\n",
    "\n",
    "# gdown을 사용하여 파일 다운로드\n",
    "import gdown\n",
    "\n",
    "# 다운로드할 파일의 Google Drive 파일 ID와 저장할 경로 설정\n",
    "file_id = \"1e541AXa81DqeD-XpPhNWnWlewo8yjbOa\"\n",
    "output = \"./data/creditcard.csv\"\n",
    "\n",
    "# 파일 다운로드 수행\n",
    "gdown.download(id=file_id, output=output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqEmmmzZf34i"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXT-DbuLEStn"
   },
   "outputs": [],
   "source": [
    "# 필요 라이브러리 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seaborn을 사용한 플롯 스타일 설정\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R66Zb1C9f-ID"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5GxGjTsf9wl"
   },
   "outputs": [],
   "source": [
    "def torch_seed(random_seed: int):\n",
    "    \"\"\"Torch 및 기타 라이브러리의 시드를 고정하여 재현성을 확보합니다.\"\"\"\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, \n",
    "    criterion: torch.nn.Module, optimizer: torch.optim.Optimizer, \n",
    "    log_interval: int, device: str\n",
    ") -> float:\n",
    "    \"\"\"모델을 학습시키고 평균 손실을 반환합니다.\"\"\"\n",
    "\n",
    "    total_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for i, (inputs, _) in enumerate(dataloader):\n",
    "\n",
    "        # convert device\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(inputs, outputs).mean()\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # log learning history\n",
    "        if i % log_interval == 0 or (i+1) == len(dataloader):\n",
    "            print(f\"{'TRAIN':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
    "\n",
    "    # average loss\n",
    "    avg_loss = np.mean(total_loss)\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, \n",
    "    criterion: torch.nn.Module, log_interval: int, device: str\n",
    ") -> tuple:\n",
    "    \"\"\"모델을 평가하고 AUROC 점수 및 예측 결과를 반환합니다.\"\"\"\n",
    "\n",
    "    # for auroc\n",
    "    total_loss = []\n",
    "    total_inputs = []\n",
    "    total_targets = []\n",
    "    total_outputs = []\n",
    "\n",
    "    torch_seed(72)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            # get inputs and targets\n",
    "            total_inputs.extend(inputs.numpy())\n",
    "            total_targets.extend(targets.numpy())\n",
    "\n",
    "            # convert device\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # model outputs\n",
    "            outputs = model(inputs)\n",
    "            total_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(inputs, outputs).max(dim=-1)[0]\n",
    "            total_loss.extend(loss.cpu().numpy())\n",
    "\n",
    "            # log learning history\n",
    "            if i % log_interval == 0 or (i+1) == len(dataloader):\n",
    "                print(f\"{'TSET':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
    "\n",
    "    # total inputs, outputs, targets and loss\n",
    "    total_inputs = np.concatenate(total_inputs, axis=0)\n",
    "    total_outputs = np.concatenate(total_outputs, axis=0)\n",
    "    total_targets = np.array(total_targets).reshape(-1)\n",
    "    total_loss = np.array(total_loss).reshape(-1)\n",
    "\n",
    "    # auroc\n",
    "    if sum(total_targets) == 0:\n",
    "        auroc = 1.\n",
    "    else:\n",
    "        auroc = roc_auc_score(total_targets, total_loss)\n",
    "\n",
    "    # return\n",
    "    return auroc, total_inputs, total_outputs, total_loss\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: torch.nn.Module, trainloader: torch.utils.data.DataLoader, \n",
    "    testloader: torch.utils.data.DataLoader, criterion: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer, epochs: int, log_interval: int, \n",
    "    device: str\n",
    ") -> tuple:\n",
    "    \"\"\"모델을 학습하고 테스트하여 학습 손실 및 테스트 AUROC 히스토리를 반환합니다.\"\"\"\n",
    "\n",
    "    train_history = []\n",
    "    test_history_auroc = []\n",
    "\n",
    "    # fitting model\n",
    "    for i in range(epochs):\n",
    "        print(f'\\nEpoch: [{i+1}/{epochs}]')\n",
    "        train_loss = train(\n",
    "            model        = model,\n",
    "            dataloader   = trainloader,\n",
    "            criterion    = criterion,\n",
    "            optimizer    = optimizer,\n",
    "            log_interval = log_interval,\n",
    "            device       = device\n",
    "        )\n",
    "\n",
    "        test_auroc, total_inputs, total_outputs, total_loss = test(\n",
    "            model        = model,\n",
    "            dataloader   = testloader,\n",
    "            criterion    = criterion,\n",
    "            log_interval = log_interval,\n",
    "            device       = device\n",
    "        )\n",
    "\n",
    "        print(f'\\nTest AUROC: {test_auroc:.4f}')\n",
    "\n",
    "        train_history.append(train_loss)\n",
    "        test_history_auroc.append(test_auroc)\n",
    "\n",
    "    return train_history, test_history_auroc\n",
    "\n",
    "\n",
    "def plot_history(\n",
    "    all_train_history: list, all_test_history_auroc: list, all_exp_name: list\n",
    ") -> None:\n",
    "    \"\"\"학습 손실 및 테스트 AUROC 히스토리를 시각화합니다.\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "    # train line plot\n",
    "    for i, (train_h, exp_name) in enumerate(zip(all_train_history, all_exp_name)):\n",
    "        sns.lineplot(\n",
    "            x     = range(1, len(train_h)+1),\n",
    "            y     = train_h,\n",
    "            label = exp_name,\n",
    "            ax    = ax[0]\n",
    "        )\n",
    "\n",
    "    # test AUROC lineplot\n",
    "    for i, (test_h, exp_name) in enumerate(zip(all_test_history_auroc, all_exp_name)):\n",
    "        sns.lineplot(\n",
    "            x     = range(1, len(test_h)+1),\n",
    "            y     = test_h,\n",
    "            label = exp_name,\n",
    "            ax    = ax[1]\n",
    "        )\n",
    "\n",
    "    # set y axis label\n",
    "    ax[0].set_ylabel('MSE Loss')\n",
    "    ax[1].set_ylabel('AUROC')\n",
    "\n",
    "    # set x axis label\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "\n",
    "    # set title\n",
    "    ax[0].set_title('Train loss history')\n",
    "    ax[1].set_title('Test AUROC history')\n",
    "\n",
    "    # set y value limit\n",
    "    max_train = np.max(all_train_history)\n",
    "\n",
    "    ax[0].set_ylim(0, max_train+0.01)\n",
    "    ax[1].set_ylim(0, 1)\n",
    "\n",
    "    # set legend\n",
    "    ax[0].legend(loc='upper left')\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGDwgU6Bx-Xk"
   },
   "source": [
    "## Configuration for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXiq4BOkx9yN"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    설정 클래스\n",
    "    \"\"\"\n",
    "\n",
    "    # dataset 관련 parameters\n",
    "    datapath = './data/creditcard.csv'  # 데이터 파일 경로\n",
    "\n",
    "    # training 관련 parameters\n",
    "    epochs = 15                        # 총 학습 에폭 수\n",
    "    batch_size = 512                   # 학습 데이터 배치 크기\n",
    "    test_batch_size = 128              # 테스트 데이터 배치 크기\n",
    "    learning_rate = 0.001              # 학습률\n",
    "    num_workers = 2                    # 데이터 로딩을 위한 워커 수\n",
    "    log_interval = 2000                # 학습 로그를 출력할 간격\n",
    "\n",
    "    # device\n",
    "    device = 'cuda'                    # 학습을 위한 디바이스 (cuda 또는 cpu)\n",
    "\n",
    "    # seed\n",
    "    seed = 72                          # 시드 값 (재현성 확보를 위해 고정)\n",
    "\n",
    "# Config 클래스의 인스턴스를 생성\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRUckH_vyNIX"
   },
   "source": [
    "## Load dataset and dataloader\n",
    "\n",
    "**Feature Description**\n",
    "- **Time**: Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
    "- **V{ID}**: PCA results\n",
    "- **Amount**: Transaction amount\n",
    "- **Class**: 1 for fraudulent transactions, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NunGNlssgz0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfg.datapath)\n",
    "print('df.shape: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2vYC1WlyTsp"
   },
   "outputs": [],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj4hcNzgynzK"
   },
   "outputs": [],
   "source": [
    "# drop NaN\n",
    "df = df.dropna()\n",
    "print('df.shape: ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkMYq9PB5eG_"
   },
   "outputs": [],
   "source": [
    "# target\n",
    "pd.concat([df['Class'].value_counts(), df['Class'].value_counts(normalize=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXblLcKQ3LPP"
   },
   "source": [
    "### Split dataset into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN1ts-o23IVj"
   },
   "outputs": [],
   "source": [
    "# 'Class'가 0인 인덱스를 추출하고, 이를 학습용 인덱스와 나머지 인덱스로 분할\n",
    "# 이 과정에서 전체 데이터셋 중 10%를 테스트셋으로 분할\n",
    "train_idx, _ = train_test_split(\n",
    "    df[df['Class'] == 0].index.values, \n",
    "    test_size=0.1, \n",
    "    random_state=cfg.seed\n",
    ")\n",
    "\n",
    "# 결과 출력 (optional)\n",
    "print(f\"Number of training indices: {len(train_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEtyv8H84GaN"
   },
   "outputs": [],
   "source": [
    "# 학습용 데이터프레임과 테스트용 데이터프레임을 생성\n",
    "df_train = df.iloc[train_idx, :]  # 학습용 인덱스를 사용하여 학습용 데이터프레임을 생성\n",
    "df_test = df.drop(train_idx, axis=0)  # 학습용 인덱스를 제외한 나머지 데이터로 테스트용 데이터프레임을 생성\n",
    "\n",
    "# 학습용 데이터셋에서 특징 행렬(X)과 라벨 벡터(y)를 분리\n",
    "X_train = df_train.drop('Class', axis=1).values  # 'Class' 열을 제외한 나머지 열을 특징 행렬로 사용\n",
    "y_train = df_train['Class'].values  # 'Class' 열을 라벨 벡터로 사용\n",
    "\n",
    "# 테스트용 데이터셋에서 특징 행렬(X)과 라벨 벡터(y)를 분리\n",
    "X_test = df_test.drop('Class', axis=1).values  # 'Class' 열을 제외한 나머지 열을 특징 행렬로 사용\n",
    "y_test = df_test['Class'].values  # 'Class' 열을 라벨 벡터로 사용\n",
    "\n",
    "# 데이터셋의 크기를 출력\n",
    "print('X_train.shape: ', X_train.shape)  # 학습용 특징 행렬의 크기를 출력\n",
    "print('y_train.shape: ', y_train.shape)  # 학습용 라벨 벡터의 크기를 출력\n",
    "print('X_test.shape: ', X_test.shape)  # 테스트용 특징 행렬의 크기를 출력\n",
    "print('y_test.shape: ', y_test.shape)  # 테스트용 라벨 벡터의 크기를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8DAuYZk-9Tw"
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAqn2eh2_A1I"
   },
   "outputs": [],
   "source": [
    "# MinMaxScaler를 사용하여 특징 행렬을 [0, 1] 범위로 정규화\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 학습용 데이터의 특징 행렬을 정규화\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트용 데이터의 특징 행렬을 학습용 데이터의 스케일에 맞춰 정규화\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPLHgxR-2xxz"
   },
   "outputs": [],
   "source": [
    "# TensorDataset을 사용하여 학습용 및 테스트용 텐서 데이터셋 생성\n",
    "trainset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "testset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "# DataLoader를 사용하여 학습용 및 테스트용 데이터로더 생성\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=cfg.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=cfg.num_workers\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=cfg.test_batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=cfg.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmrl77Ct5qoR"
   },
   "source": [
    "## Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7LHiji620Ay"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, dims: list):\n",
    "        \"\"\"\n",
    "        AutoEncoder 클래스 초기화.\n",
    "        :param input_dim: 입력 데이터의 차원\n",
    "        :param dims: 인코더 및 디코더의 각 층의 노드 수 리스트\n",
    "        \"\"\"\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # 인코더와 디코더의 층 크기를 설정\n",
    "        dims = [input_dim] + dims\n",
    "\n",
    "        # 인코더 및 디코더 생성\n",
    "        self.enc = nn.Sequential(*self.build_layer(dims=dims))  # 인코더 층\n",
    "        self.dec = nn.Sequential(*self.build_layer(dims=dims[::-1], up=True))  # 디코더 층\n",
    "        self.output = nn.Linear(in_features=dims[0], out_features=input_dim)  # 최종 출력층\n",
    "\n",
    "    def build_layer(self, dims, up=False):\n",
    "        \"\"\"\n",
    "        인코더 또는 디코더 층을 생성하는 함수.\n",
    "        :param dims: 각 층의 노드 수 리스트\n",
    "        :param up: 디코더 층 생성을 위한 플래그\n",
    "        :return: 생성된 층 리스트\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "\n",
    "        for i in range(1, len(dims)):\n",
    "            layer = [\n",
    "                nn.Linear(\n",
    "                    in_features=dims[i - 1],\n",
    "                    out_features=dims[i]\n",
    "                ),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "            layers.extend(layer)\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def encoder(self, x):\n",
    "        \"\"\"\n",
    "        인코더를 통해 입력 데이터를 변환.\n",
    "        :param x: 입력 데이터\n",
    "        :return: 인코더를 거친 출력\n",
    "        \"\"\"\n",
    "        return self.enc(x)\n",
    "\n",
    "    def decoder(self, x):\n",
    "        \"\"\"\n",
    "        디코더를 통해 인코더 출력 데이터를 원래 차원으로 변환.\n",
    "        :param x: 인코더 출력 데이터\n",
    "        :return: 디코더를 거친 최종 출력\n",
    "        \"\"\"\n",
    "        x = self.dec(x)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)  # sigmoid 활성화 함수 사용\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수.\n",
    "        :param x: 입력 데이터\n",
    "        :return: AutoEncoder의 최종 출력\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qB1W5nSn9KYk"
   },
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "torch_seed(cfg.seed)\n",
    "\n",
    "# AutoEncoder 모델 생성\n",
    "ae = AutoEncoder(input_dim=X_train.shape[1], dims=[64, 32, 16])\n",
    "\n",
    "# 모델을 지정된 장치(CPU 또는 GPU)로 이동\n",
    "ae.to(cfg.device)\n",
    "\n",
    "# 모델 로드 메시지 출력\n",
    "print('Load Auto-Encoder')\n",
    "\n",
    "# 모델 파라미터의 총 개수를 출력\n",
    "print('The number of model parameters: ', sum(p.numel() for p in ae.parameters()))\n",
    "\n",
    "# 손실 함수 설정\n",
    "# MSELoss (Mean Squared Error Loss) 함수를 사용하며, reduction을 'none'으로 설정하여 개별 손실 값을 유지\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "# 옵티마이저 설정\n",
    "# Adam 옵티마이저를 사용하며, 학습률은 cfg에서 설정된 learning_rate를 사용\n",
    "optimizer = Adam(ae.parameters(), lr=cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYUFs_TR_nzP"
   },
   "outputs": [],
   "source": [
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-Hp42wh9aod"
   },
   "outputs": [],
   "source": [
    "# trainloader에서 첫 번째 배치의 데이터를 가져옴\n",
    "inputs, targets = next(iter(trainloader))\n",
    "\n",
    "# 입력 데이터를 지정된 장치(CPU 또는 GPU)로 이동\n",
    "inputs = inputs.to(cfg.device)\n",
    "\n",
    "# 입력 데이터의 형태를 출력\n",
    "print('inputs.shape: ', inputs.shape)\n",
    "\n",
    "# 모델에 입력 데이터를 전달하여 출력을 계산\n",
    "outputs = ae(inputs)\n",
    "\n",
    "# 출력 데이터의 형태를 출력\n",
    "print('outputs.shape: ', outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuTBKBlM99Qo"
   },
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "torch_seed(cfg.seed)\n",
    "\n",
    "# AutoEncoder 모델 학습 및 평가\n",
    "train_history, test_history_auroc = fit(\n",
    "    model        = ae,                 # 학습할 모델\n",
    "    trainloader  = trainloader,        # 학습 데이터 로더\n",
    "    testloader   = testloader,         # 테스트 데이터 로더\n",
    "    criterion    = criterion,          # 손실 함수\n",
    "    optimizer    = optimizer,          # 옵티마이저\n",
    "    epochs       = cfg.epochs,         # 학습 에폭 수\n",
    "    log_interval = cfg.log_interval,   # 로그 출력 간격\n",
    "    device       = cfg.device          # 학습에 사용할 디바이스\n",
    ")\n",
    "\n",
    "# 학습 결과 출력\n",
    "print(\"Training completed.\")\n",
    "print(\"Train History: \", train_history)\n",
    "print(\"Test AUROC History: \", test_history_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkdrkuq-9sAP"
   },
   "outputs": [],
   "source": [
    "# 학습 및 테스트 히스토리를 리스트에 추가\n",
    "all_train_history = [train_history]\n",
    "all_test_history_auroc = [test_history_auroc]\n",
    "all_exp_name = ['AE']\n",
    "\n",
    "# 학습 및 테스트 히스토리 시각화\n",
    "plot_history(\n",
    "    all_train_history      = all_train_history,\n",
    "    all_test_history_auroc = all_test_history_auroc,\n",
    "    all_exp_name           = all_exp_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajJj4nm0FDRh"
   },
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용하여 테스트 데이터에 대한 평가 수행\n",
    "test_auroc, total_inputs, total_outputs, total_loss = test(\n",
    "    model        = ae,                 # 평가할 모델\n",
    "    dataloader   = testloader,         # 테스트 데이터 로더\n",
    "    criterion    = criterion,          # 손실 함수\n",
    "    log_interval = cfg.log_interval,   # 로그 출력 간격\n",
    "    device       = cfg.device          # 평가에 사용할 디바이스\n",
    ")\n",
    "\n",
    "# 테스트 결과 출력\n",
    "print(f\"Test AUROC: {test_auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_QRFq2mHMEx"
   },
   "outputs": [],
   "source": [
    "# MinMax 스케일링 함수 정의\n",
    "def minmax(x):\n",
    "    \"\"\"\n",
    "    입력된 값들을 Min-Max 스케일링하여 [0, 1] 범위로 변환합니다.\n",
    "    :param x: 입력 데이터\n",
    "    :return: 스케일링된 데이터\n",
    "    \"\"\"\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "# 테스트 데이터프레임에 예측된 이상 점수를 추가\n",
    "df_test['pred'] = minmax(total_loss)\n",
    "\n",
    "# Boxplot을 사용하여 클래스별 이상 점수 분포 시각화\n",
    "sns.boxplot(x='Class', y='pred', hue='Class', data=df_test)\n",
    "\n",
    "# 그래프 제목 및 레이블 설정\n",
    "plt.title('Anomaly Score Distribution')\n",
    "plt.xticks([0, 1], ['Normal', 'Abnormal'])\n",
    "plt.ylabel('Anomaly Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
