{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ihXL84IZP7Ii",
   "metadata": {
    "id": "ihXL84IZP7Ii"
   },
   "source": [
    "# [ LG에너지솔루션 DX Expert 양성과정 - Auto-Encoder #3]\n",
    "\n",
    "Deep Auto-Encoder를 활용한 time-series anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204103f-856a-4faf-b36f-5f00d2e7b0ef",
   "metadata": {},
   "source": [
    "## 강의 복습\n",
    "강의자료: Deep Auto-Encoder\n",
    "- `RNN Auto-Encoder`: 순차 데이터를 복원하는 오토 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb73c6-7c4a-49eb-9a37-7c5985adb960",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hwk0702/2024_LG_ES_External_Lecture/blob/main/240702_Deep_Auto_Encoder/image/RNNAE01.png?raw=true\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12744aa2-7cd5-494a-a8bd-f6214034b1be",
   "metadata": {},
   "source": [
    "## 실습 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18715d67-734e-4337-b1b8-d4ca08bd9a7d",
   "metadata": {},
   "source": [
    "1. 본 실습에서는 RNN Auto-Encoder를 활용하여 시계열 이상 탐지를 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25bbf1f-d324-4df4-9cb3-36bb12f87b31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0072fa",
   "metadata": {
    "id": "db0072fa"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea49a2",
   "metadata": {
    "id": "feea49a2"
   },
   "outputs": [],
   "source": [
    "# 데이터 처리 및 모델 학습에 필요한 라이브러리 임포트\n",
    "import numpy as np                # 수치 연산을 위한 라이브러리\n",
    "import pandas as pd               # 데이터 처리를 위한 라이브러리\n",
    "import os                         # 운영체제와 상호작용하기 위한 라이브러리\n",
    "import random                     # 난수 생성을 위한 라이브러리\n",
    "\n",
    "import torch                      # PyTorch 라이브러리\n",
    "import torch.nn as nn             # 신경망 모듈\n",
    "import torch.nn.functional as F   # 신경망 함수\n",
    "from torch.utils.data import Dataset, DataLoader  # 데이터셋 및 데이터로더 모듈\n",
    "from torch.optim import Adam, SGD  # 옵티마이저 모듈\n",
    "\n",
    "from sklearn.metrics import average_precision_score  # ROC AUC 점수 계산을 위한 메트릭\n",
    "from itertools import groupby, accumulate  # 반복자 함수\n",
    "\n",
    "# 시각화 라이브러리 임포트\n",
    "import matplotlib.pyplot as plt   # 데이터 시각화를 위한 라이브러리\n",
    "import seaborn as sns             # 데이터 시각화를 위한 고급 라이브러리\n",
    "\n",
    "# Seaborn의 플롯 스타일 설정\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cd08a",
   "metadata": {
    "id": "b33cd08a"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9b15d",
   "metadata": {
    "id": "7fe9b15d"
   },
   "outputs": [],
   "source": [
    "def torch_seed(random_seed: int):\n",
    "    \"\"\"Torch 및 기타 라이브러리의 시드를 고정하여 재현성을 확보합니다.\"\"\"\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "\n",
    "def calc_point2point(predict, actual):\n",
    "    \"\"\"\n",
    "    calculate f1 score by predict and actual.\n",
    "    Args:\n",
    "        predict (np.ndarray): the predict label\n",
    "        actual (np.ndarray): np.ndarray\n",
    "    \"\"\"\n",
    "    TP = np.sum(predict * actual)\n",
    "    TN = np.sum((1 - predict) * (1 - actual))\n",
    "    FP = np.sum(predict * (1 - actual))\n",
    "    FN = np.sum((1 - predict) * actual)\n",
    "    precision = TP / (TP + FP + 0.00001)\n",
    "    recall = TP / (TP + FN + 0.00001)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 0.00001)\n",
    "    return f1, precision, recall, TP, TN, FP, FN\n",
    "\n",
    "def bf_search(score, label, start, end=None, step_num=1, display_freq=1, verbose=True) -> object:\n",
    "    \"\"\"\n",
    "    Find the best-f1 score by searching best `threshold` in [`start`, `end`).\n",
    "    Returns:\n",
    "        list: list for results\n",
    "        float: the `threshold` for best-f1\n",
    "    \"\"\"\n",
    "    if step_num is None or end is None:\n",
    "        end = start\n",
    "        step_num = 1\n",
    "    search_step, search_range, search_lower_bound = step_num, end - start, start\n",
    "    if verbose:\n",
    "        print(\"search range: \", search_lower_bound, search_lower_bound + search_range)\n",
    "    threshold = search_lower_bound\n",
    "    m = [-1., -1., -1.]\n",
    "    m_t = 0.0\n",
    "    for i in range(search_step):\n",
    "        threshold += search_range / float(search_step)\n",
    "        predict = score > threshold\n",
    "        f1, precision, recall, _, _, _, _ = calc_point2point(predict, label)\n",
    "        if f1 > m[0]:\n",
    "            m_t = threshold\n",
    "            m[0] = f1\n",
    "            m[1] = precision\n",
    "            m[2] = recall\n",
    "        if verbose and i % display_freq == 0:\n",
    "            print(f\"cur thr: {threshold:.4f} | F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    return m, m_t\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, \n",
    "    criterion: torch.nn.Module, optimizer: torch.optim.Optimizer, \n",
    "    log_interval: int, device: str\n",
    ") -> float:\n",
    "    \"\"\"모델을 학습시키고 평균 손실을 반환합니다.\"\"\"\n",
    "\n",
    "    total_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for i, (inputs, _) in enumerate(dataloader):\n",
    "\n",
    "        # convert device\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(inputs, outputs).mean()\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # log learning history\n",
    "        if i % log_interval == 0 or (i+1) == len(dataloader):\n",
    "            print(f\"{'TRAIN':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
    "\n",
    "    # average loss\n",
    "    avg_loss = np.mean(total_loss)\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, \n",
    "    criterion: torch.nn.Module, log_interval: int, device: str\n",
    ") -> tuple:\n",
    "    \"\"\"모델을 평가하고 평가지표 점수 및 예측 결과를 반환합니다.\"\"\"\n",
    "\n",
    "    total_loss = []\n",
    "    total_inputs = []\n",
    "    total_targets = []\n",
    "    total_outputs = []\n",
    "\n",
    "    torch_seed(223)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            # get inputs and targets\n",
    "            total_inputs.extend(inputs.numpy())\n",
    "            total_targets.extend(targets.numpy())\n",
    "\n",
    "            # convert device\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # model outputs\n",
    "            outputs = model(inputs)\n",
    "            total_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(inputs, outputs).max(dim=-1)[0]\n",
    "            total_loss.extend(loss.cpu().numpy())\n",
    "\n",
    "            # log learning history\n",
    "            if i % log_interval == 0 or (i+1) == len(dataloader):\n",
    "                print(f\"{'TSET':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
    "\n",
    "    # total inputs, outputs, targets and loss\n",
    "    total_inputs = np.concatenate(total_inputs, axis=0)\n",
    "    total_outputs = np.concatenate(total_outputs, axis=0)\n",
    "    total_targets = np.array(total_targets).reshape(-1)\n",
    "    total_loss = np.array(total_loss).reshape(-1)\n",
    "\n",
    "    # auprc\n",
    "    if sum(total_targets) == 0:\n",
    "        auprc = 1.\n",
    "    else:\n",
    "        auprc = average_precision_score(total_targets, total_loss)\n",
    "\n",
    "    [f1, precision, recall], threshold = bf_search(total_loss, total_targets,\n",
    "                                                   start=np.percentile(total_loss, 50),\n",
    "                                                   end=np.percentile(total_loss, 99),\n",
    "                                                   step_num=1000,\n",
    "                                                   verbose=False)\n",
    "\n",
    "    # return\n",
    "    return f1, precision, recall, threshold, auprc, total_inputs, total_outputs, total_loss\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: torch.nn.Module, trainloader: torch.utils.data.DataLoader, \n",
    "    testloader: torch.utils.data.DataLoader, criterion: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer, epochs: int, log_interval: int, \n",
    "    device: str\n",
    ") -> tuple:\n",
    "    \"\"\"모델을 학습하고 테스트하여 학습 손실 및 테스트 F1-score 히스토리를 반환합니다.\"\"\"\n",
    "\n",
    "    train_history = []\n",
    "    test_history_f1 = []\n",
    "\n",
    "    # fitting model\n",
    "    for i in range(epochs):\n",
    "        print(f'\\nEpoch: [{i+1}/{epochs}]')\n",
    "        train_loss = train(\n",
    "            model        = model,\n",
    "            dataloader   = trainloader,\n",
    "            criterion    = criterion,\n",
    "            optimizer    = optimizer,\n",
    "            log_interval = log_interval,\n",
    "            device       = device\n",
    "        )\n",
    "\n",
    "        f1, precision, recall, threshold, auprc, total_inputs, total_outputs, total_loss = test(\n",
    "            model        = model,\n",
    "            dataloader   = testloader,\n",
    "            criterion    = criterion,\n",
    "            log_interval = log_interval,\n",
    "            device       = device\n",
    "        )\n",
    "\n",
    "        print(f'\\nTest Treshold: {threshold:.4f}, F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, AUPRC: {auprc:.4f}')\n",
    "\n",
    "        # show results\n",
    "        plt.figure(figsize=(15,4))\n",
    "        sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs')\n",
    "        sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:,0], label='reconstruction')\n",
    "        sns.lineplot(x=range(len(total_loss)), y=total_loss, label='anomaly score')\n",
    "\n",
    "        # set title\n",
    "        plt.title(\"testset anomal score\")\n",
    "        plt.xlabel(\"time index\")\n",
    "        plt.ylabel(\"value\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # stack history\n",
    "        train_history.append(train_loss)\n",
    "        test_history_f1.append(f1)\n",
    "\n",
    "    return train_history, test_history_f1\n",
    "\n",
    "\n",
    "def figure(\n",
    "    all_train_history: list, all_test_history_f1: list, all_exp_name: list\n",
    ") -> None:\n",
    "    \"\"\"학습 손실 및 테스트 F1-score 히스토리를 시각화합니다.\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "\n",
    "    # train line plot\n",
    "    for i, (train_h, exp_name) in enumerate(zip(all_train_history, all_exp_name)):\n",
    "        sns.lineplot(\n",
    "            x     = range(1, len(train_h)+1),\n",
    "            y     = train_h,\n",
    "            label = exp_name,\n",
    "            ax    = ax[0]\n",
    "        )\n",
    "\n",
    "    # test F1-score lineplot\n",
    "    for i, (test_h, exp_name) in enumerate(zip(all_test_history_f1, all_exp_name)):\n",
    "        sns.lineplot(\n",
    "            x     = range(1, len(test_h)+1),\n",
    "            y     = test_h,\n",
    "            label = exp_name,\n",
    "            ax    = ax[1]\n",
    "        )\n",
    "\n",
    "\n",
    "    # set y axis label\n",
    "    ax[0].set_ylabel('MSE Loss')\n",
    "    ax[1].set_ylabel('F1-score')\n",
    "\n",
    "    # set x axis label\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "\n",
    "    # set title\n",
    "    ax[0].set_title('Train loss history')\n",
    "    ax[1].set_title('Test F1-score history')\n",
    "\n",
    "    # set y value limit\n",
    "    max_train = np.max(all_train_history)\n",
    "\n",
    "    ax[0].set_ylim(0, max_train+0.01)\n",
    "    ax[1].set_ylim(0, 1)\n",
    "\n",
    "    # set legend\n",
    "    ax[0].legend(loc='upper left')\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033d254",
   "metadata": {
    "id": "1033d254"
   },
   "source": [
    "# Configuration for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e112de",
   "metadata": {
    "id": "d7e112de"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    실험 설정을 담고 있는 클래스\n",
    "    \"\"\"\n",
    "\n",
    "    # dataset 관련 parameters\n",
    "    window = 100        # 윈도우 크기 (시계열 데이터의 한 구간 크기)\n",
    "    stride = 10         # 스트라이드 크기 (윈도우가 이동하는 간격)\n",
    "\n",
    "    # make dataset\n",
    "    sin_sequence = 100  # 사인 곡선 시퀀스 길이\n",
    "    repeat = 30         # 사인 곡선을 반복할 횟수\n",
    "\n",
    "    # synthesis anomaly setting\n",
    "    anomaly_sequence = 10  # 이상치 시퀀스 길이\n",
    "    anomaly_region = 5     # 이상치 영역 크기\n",
    "\n",
    "    # training 관련 parameters\n",
    "    epochs = 20            # 총 학습 에폭 수\n",
    "    batch_size = 8         # 학습 데이터 배치 크기\n",
    "    test_batch_size = 128  # 테스트 데이터 배치 크기\n",
    "    learning_rate = 0.001  # 학습률\n",
    "    num_workers = 2        # 데이터 로딩을 위한 워커 수\n",
    "    log_interval = 2000    # 로그 출력 간격\n",
    "\n",
    "    # device\n",
    "    device = 'cuda'        # 학습을 위한 디바이스 (cuda 또는 cpu)\n",
    "\n",
    "    # seed\n",
    "    seed = 223             # 시드 값 (재현성 확보를 위해 고정)\n",
    "\n",
    "# Config 클래스의 인스턴스를 생성\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187001e",
   "metadata": {
    "id": "9187001e"
   },
   "source": [
    "## make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30532b65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "30532b65",
    "outputId": "3edaa64f-8ec3-4a3d-d88a-a5d2ba5b36dd"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터셋 생성\n",
    "x_train = np.array([np.sin(i * np.pi) for i in np.linspace(start=-2, stop=2, num=cfg.sin_sequence)] * cfg.repeat)\n",
    "x_train = x_train + np.random.random(cfg.sin_sequence * cfg.repeat)  # 노이즈 추가\n",
    "y_train = np.zeros(len(x_train))  # 학습 데이터셋 레이블 (모두 정상)\n",
    "\n",
    "# 테스트 데이터셋 생성\n",
    "x_test = x_train[:1000].copy()  # 학습 데이터셋의 일부를 복사하여 테스트 데이터셋 생성\n",
    "y_test = np.zeros(len(x_test))  # 테스트 데이터셋 레이블 (모두 정상)\n",
    "\n",
    "# 시드 설정\n",
    "torch_seed(cfg.seed)\n",
    "\n",
    "# 이상치 인덱스 선택\n",
    "anomaly_idx = np.random.choice(range(len(x_test)), size=cfg.anomaly_region)\n",
    "\n",
    "# 이상치 삽입\n",
    "for ano_idx in anomaly_idx:\n",
    "    x_test[ano_idx:ano_idx + cfg.anomaly_sequence] = x_test[ano_idx:ano_idx + cfg.anomaly_sequence] * 2  # 이상치 삽입\n",
    "    y_test[ano_idx:ano_idx + cfg.anomaly_sequence] = 1  # 이상치 레이블 설정\n",
    "\n",
    "# 데이터셋 시각화\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 7))\n",
    "\n",
    "# 학습 데이터셋 시각화\n",
    "sns.lineplot(x=range(len(x_train)), y=x_train, ax=ax[0])\n",
    "ax[0].set_title('trainset values')\n",
    "ax[0].set_xlabel('time index')\n",
    "\n",
    "# 테스트 데이터셋 시각화\n",
    "sns.lineplot(x=range(len(x_test)), y=x_test, ax=ax[1])\n",
    "for ano_idx in anomaly_idx:\n",
    "    ax[1].axvspan(ano_idx, ano_idx + cfg.anomaly_sequence, color='red', alpha=0.2)  # 이상치 영역 강조\n",
    "ax[1].set_title('testset values')\n",
    "ax[1].set_xlabel('time index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed64d5",
   "metadata": {
    "id": "05ed64d5"
   },
   "outputs": [],
   "source": [
    "class TSADDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, window: int, stride: int):\n",
    "        \"\"\"\n",
    "        TSADDataset 클래스 초기화\n",
    "        :param X: 입력 데이터 (numpy 배열)\n",
    "        :param y: 타겟 레이블 (numpy 배열)\n",
    "        :param window: 윈도우 크기\n",
    "        :param stride: 스트라이드 크기\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.window = window\n",
    "        self.stride = stride\n",
    "\n",
    "        # 시작 인덱스 리스트 생성\n",
    "        self.start_index = list(range(0, len(self.X) - window + 1, stride))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋에서 하나의 샘플을 가져옵니다.\n",
    "        :param idx: 샘플 인덱스\n",
    "        :return: 입력 데이터와 타겟 레이블\n",
    "        \"\"\"\n",
    "        # 시작 인덱스 설정\n",
    "        s_idx = self.start_index[idx]\n",
    "\n",
    "        # 입력 데이터와 타겟 레이블 설정\n",
    "        input = self.X[s_idx:s_idx + self.window]\n",
    "        target = self.y[s_idx:s_idx + self.window]\n",
    "\n",
    "        # 입력 데이터를 FloatTensor로 변환하고, 마지막 차원에 채널 차원 추가\n",
    "        input = torch.FloatTensor(input).unsqueeze(-1)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 샘플 수를 반환합니다.\n",
    "        :return: 데이터셋 샘플 수\n",
    "        \"\"\"\n",
    "        return len(self.start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c2af5",
   "metadata": {
    "id": "a66c2af5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 학습 데이터셋 정의\n",
    "trainset = TSADDataset(\n",
    "    X=x_train,         # 학습 입력 데이터\n",
    "    y=y_train,         # 학습 타겟 레이블\n",
    "    window=cfg.window, # 윈도우 크기\n",
    "    stride=cfg.stride  # 스트라이드 크기\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋 정의\n",
    "testset = TSADDataset(\n",
    "    X=x_test,          # 테스트 입력 데이터\n",
    "    y=y_test,          # 테스트 타겟 레이블\n",
    "    window=cfg.window, # 윈도우 크기\n",
    "    stride=cfg.window  # 스트라이드 크기 (이 설정으로 전체 윈도우가 겹치지 않음)\n",
    ")\n",
    "\n",
    "# 학습 데이터로더 정의\n",
    "trainloader = DataLoader(\n",
    "    trainset,                      # 학습 데이터셋\n",
    "    batch_size=cfg.batch_size,     # 배치 크기\n",
    "    shuffle=True,                  # 데이터 순서 섞기 여부\n",
    "    num_workers=cfg.num_workers    # 데이터 로딩을 위한 워커 수\n",
    ")\n",
    "\n",
    "# 테스트 데이터로더 정의\n",
    "testloader = DataLoader(\n",
    "    testset,                       # 테스트 데이터셋\n",
    "    batch_size=cfg.test_batch_size,# 배치 크기\n",
    "    shuffle=False,                 # 데이터 순서 섞지 않기\n",
    "    num_workers=cfg.num_workers    # 데이터 로딩을 위한 워커 수\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13c0e8",
   "metadata": {
    "id": "fa13c0e8"
   },
   "source": [
    "# RNN Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87337d",
   "metadata": {
    "id": "5d87337d"
   },
   "outputs": [],
   "source": [
    "class RNNAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_size: int, num_layers: int):\n",
    "        \"\"\"\n",
    "        RNNAutoEncoder 클래스 초기화\n",
    "        :param input_dim: 입력 차원\n",
    "        :param hidden_size: RNN의 은닉 상태 크기\n",
    "        :param num_layers: RNN의 레이어 수\n",
    "        \"\"\"\n",
    "        super(RNNAutoEncoder, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.enc = nn.RNN(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.dec = nn.RNN(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 출력 레이어\n",
    "        self.output = nn.Linear(in_features=hidden_size, out_features=input_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        \"\"\"\n",
    "        인코더 함수\n",
    "        :param x: 입력 데이터\n",
    "        :return: 인코더 출력 및 은닉 상태\n",
    "        \"\"\"\n",
    "        out, hidden = self.enc(x)\n",
    "        return out, hidden\n",
    "\n",
    "    def decoder(self, x, hidden):\n",
    "        \"\"\"\n",
    "        디코더 함수\n",
    "        :param x: 입력 데이터\n",
    "        :param hidden: 인코더의 은닉 상태\n",
    "        :return: 디코더 출력 및 은닉 상태\n",
    "        \"\"\"\n",
    "        out, hidden = self.dec(x, hidden)\n",
    "        out = self.output(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수\n",
    "        :param x: 입력 데이터\n",
    "        :return: 재구성된 출력\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, dims = x.size()\n",
    "\n",
    "        # 인코더\n",
    "        out, hidden = self.encoder(x)\n",
    "\n",
    "        # 디코더\n",
    "        x_rec = torch.zeros_like(x).to(x.device)\n",
    "        x_dec = torch.zeros((batch_size, 1, dims), dtype=torch.float).to(x.device)\n",
    "        for i in range(seq_len):\n",
    "            out_dec_i, hidden = self.decoder(x_dec, hidden)\n",
    "            x_rec[:, i, :] = out_dec_i[:, 0, :]\n",
    "            x_dec = out_dec_i\n",
    "\n",
    "        return x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7196738",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7196738",
    "outputId": "8cbfd1bf-2da7-41b4-b8d4-5ef55df63ad3"
   },
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "torch_seed(cfg.seed)\n",
    "\n",
    "# RNN AutoEncoder 모델 생성\n",
    "rae = RNNAutoEncoder(input_dim=1, hidden_size=32, num_layers=2)\n",
    "\n",
    "# 모델을 지정된 장치(CPU 또는 GPU)로 이동\n",
    "rae.to(cfg.device)\n",
    "\n",
    "# 모델 로드 메시지 출력\n",
    "print('Load RNN Auto-Encoder')\n",
    "\n",
    "# 모델 파라미터의 총 개수를 출력\n",
    "print('The number of model parameters: ', sum(p.numel() for p in rae.parameters()))\n",
    "\n",
    "# 손실 함수 설정\n",
    "# MSELoss (Mean Squared Error Loss) 함수를 사용하며, reduction을 'none'으로 설정하여 개별 손실 값을 유지\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "# 옵티마이저 설정\n",
    "# Adam 옵티마이저를 사용하며, 학습률은 cfg에서 설정된 learning_rate를 사용\n",
    "optimizer = Adam(rae.parameters(), lr=cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6386a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "be6386a4",
    "outputId": "2609a9ee-658b-4a3e-e6d8-1bc33fb33791",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "torch_seed(cfg.seed)\n",
    "\n",
    "# RNNAutoEncoder 모델 학습 및 평가\n",
    "train_history_rae, test_history_f1_rae = fit(\n",
    "    model=rae,                  # 학습할 모델\n",
    "    trainloader=trainloader,    # 학습 데이터 로더\n",
    "    testloader=testloader,      # 테스트 데이터 로더\n",
    "    criterion=criterion,        # 손실 함수\n",
    "    optimizer=optimizer,        # 옵티마이저\n",
    "    epochs=cfg.epochs,          # 학습 에폭 수\n",
    "    log_interval=cfg.log_interval,  # 로그 출력 간격\n",
    "    device=cfg.device           # 학습에 사용할 디바이스\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcfb20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "66dcfb20",
    "outputId": "df2806f1-5d34-4b0b-f472-35b99d284e45"
   },
   "outputs": [],
   "source": [
    "# 학습 및 평가 히스토리 리스트 정의\n",
    "all_train_history = [train_history_rae]\n",
    "all_test_history_f1 = [test_history_f1_rae]\n",
    "all_exp_name = ['RAE']\n",
    "\n",
    "# 학습 및 평가 히스토리 시각화\n",
    "figure(\n",
    "    all_train_history=all_train_history,          # 모든 학습 손실 히스토리 리스트\n",
    "    all_test_history_f1=all_test_history_f1,      # 모든 테스트 F1-score 히스토리 리스트\n",
    "    all_exp_name=all_exp_name  # 모든 실험 이름 리스트\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f63d",
   "metadata": {
    "id": "f671f63d"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef8355",
   "metadata": {
    "id": "4bef8355"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터셋 정의\n",
    "trainset = TSADDataset(\n",
    "    X=x_train,         # 학습 입력 데이터\n",
    "    y=y_train,         # 학습 타겟 레이블\n",
    "    window=cfg.window, # 윈도우 크기\n",
    "    stride=cfg.window  # 스트라이드 크기 (이 설정으로 전체 윈도우가 겹치지 않음)\n",
    ")\n",
    "\n",
    "# 학습 데이터로더 정의\n",
    "trainloader = DataLoader(\n",
    "    trainset,                      # 학습 데이터셋\n",
    "    batch_size=cfg.batch_size,     # 배치 크기\n",
    "    shuffle=False,                 # 데이터 순서 섞지 않기\n",
    "    num_workers=cfg.num_workers    # 데이터 로딩을 위한 워커 수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d684df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "16d684df",
    "outputId": "d56edf46-8e1d-43d2-860a-53030cdab36b"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터에 대한 모델 평가\n",
    "_, _, _, _, _, total_inputs, total_outputs, total_loss = test(\n",
    "    model=rae,                    # 평가할 모델\n",
    "    dataloader=trainloader,       # 학습 데이터 로더\n",
    "    criterion=criterion,          # 손실 함수\n",
    "    log_interval=cfg.log_interval, # 로그 출력 간격\n",
    "    device=cfg.device             # 평가에 사용할 디바이스\n",
    ")\n",
    "\n",
    "# 결과 시각화\n",
    "fig, ax = plt.subplots(figsize=(30, 5))\n",
    "\n",
    "# 입력 데이터 시각화\n",
    "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:, 0], label='inputs', ax=ax)\n",
    "\n",
    "# 재구성된 출력 데이터 시각화\n",
    "sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:, 0], label='reconstruction', ax=ax)\n",
    "\n",
    "# 그래프 제목 및 레이블 설정\n",
    "ax.set_title('Train results', size=20)\n",
    "ax.set_xlabel('Time index', size=20)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a648f43",
   "metadata": {
    "id": "3a648f43"
   },
   "outputs": [],
   "source": [
    "def anomaly_region(anomaly_score, threshold):\n",
    "    \"\"\"\n",
    "    이상치 점수를 기반으로 이상치 영역의 시작과 끝 인덱스를 계산하는 함수\n",
    "    :param anomaly_score: 이상치 점수 배열\n",
    "    :param threshold: 이상치로 간주할 임계값\n",
    "    :return: 시작 인덱스 리스트와 끝 인덱스 리스트\n",
    "    \"\"\"\n",
    "    # 이상치 점수가 임계값을 초과하는지 여부를 그룹화하여 누적 합 계산\n",
    "    indices = list(accumulate(len(list(g)) for i, g in groupby((anomaly_score > threshold))))\n",
    "\n",
    "    # 시작 인덱스 계산 (이상치가 True에서 False로 바뀌는 지점)\n",
    "    starts = indices[:len(indices) // 2 * 2: 2]\n",
    "\n",
    "    # 끝 인덱스 계산 (이상치가 False에서 True로 바뀌는 지점)\n",
    "    stops = [i - 1 for i in indices[1::2]]\n",
    "\n",
    "    return starts, stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a8101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "be8a8101",
    "outputId": "1b4091c2-4539-46aa-b08f-9388f01d3fc2"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 모델 평가\n",
    "_, _, _, threshold, _, total_inputs, total_outputs, total_loss = test(\n",
    "    model=rae,                    # 평가할 모델\n",
    "    dataloader=testloader,        # 테스트 데이터 로더\n",
    "    criterion=criterion,          # 손실 함수\n",
    "    log_interval=cfg.log_interval, # 로그 출력 간격\n",
    "    device=cfg.device             # 평가에 사용할 디바이스\n",
    ")\n",
    "\n",
    "# 결과 시각화\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 7))\n",
    "\n",
    "# 입력 데이터, 재구성된 출력 데이터, 이상치 점수 시각화\n",
    "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:, 0], label='inputs', ax=ax[0])\n",
    "sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:, 0], label='reconstruction', ax=ax[0])\n",
    "sns.lineplot(x=range(len(total_loss)), y=total_loss, label='anomaly score', ax=ax[0])\n",
    "ax[0].axhline(threshold, color='red', linestyle=':', label='threshold')\n",
    "ax[0].set_title('Test result')\n",
    "ax[0].set_xlabel('Time index')\n",
    "ax[0].legend()\n",
    "\n",
    "# Ground truth 이상치 영역 시각화\n",
    "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:, 0], label='inputs', ax=ax[1])\n",
    "for ano_idx in anomaly_idx:\n",
    "    ax[1].axvspan(ano_idx, ano_idx + cfg.anomaly_sequence, color='red', alpha=0.2)\n",
    "ax[1].set_title('Ground truth anomaly regions')\n",
    "ax[1].set_xlabel('Time index')\n",
    "\n",
    "# 예측된 이상치 영역 시각화\n",
    "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:, 0], label='inputs', ax=ax[2])\n",
    "starts, stops = anomaly_region(total_loss, threshold=0.5)\n",
    "for start_idx, end_idx in zip(starts, stops):\n",
    "    ax[2].axvspan(start_idx, end_idx, color='green', alpha=0.2)\n",
    "ax[2].set_title('Prediction anomaly regions')\n",
    "ax[2].set_xlabel('Time index')\n",
    "\n",
    "# 그래프 제목 및 레이블 설정\n",
    "plt.title(\"Test set anomaly score\")\n",
    "plt.xlabel(\"Time index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9c48b-afe7-43e8-8b50-9a0e7bd3bdca",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
